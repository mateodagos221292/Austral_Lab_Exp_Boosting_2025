# Austral_Lab_Exp_Boosting_2025
Repo del Experimento de metodos de Boosting

# M√©todos de Boosting en LightGBM: GBDT vs Random Forest vs DART

Trabajo de laboratorio de la materia **Hyperparameter Tuning** (Problema #14), donde comparamos diferentes m√©todos de boosting implementados en **LightGBM**:  
- Gradient Boosting Decision Trees (**GBDT**)  
- **Random Forest** (RF)  
- **DART** (Dropouts meet Multiple Additive Regression Trees)  

---

## üéØ Objetivo e hip√≥tesis

El objetivo del experimento es **comparar el desempe√±o** de los tres m√©todos de boosting de LightGBM en t√©rminos de **ganancia econ√≥mica** obtenida en el mes **2021-09**, utilizando los resultados publicados en el leaderboard p√∫blico de la competencia. 

**Hip√≥tesis inicial:**

- El m√©todo que generar√° **mayor ganancia** ser√° **GBDT**, considerando la bibliograf√≠a y el hecho de ser el m√©todo por defecto en LightGBM.   

---

## üî¨ Dise√±o experimental

El dise√±o experimental se organiz√≥ en dos grupos de trabajo (Grupo A y Grupo B) y sigui√≥ estos lineamientos principales:

1. Partir del **notebook de laboratorio senior** provisto por la c√°tedra.
2. Crear **tres notebooks** independientes, uno por cada m√©todo de boosting:
   - `GBDT`
   - `RandomForest`
   - `DART`  
   Manteniendo constantes el resto de los hiperpar√°metros para asegurar comparabilidad.
3. Ejecutar los modelos en **m√°quinas virtuales** en paralelo, variando √∫nicamente la **semilla aleatoria**.
4. Dividir el experimento en dos grupos:
   - **Grupo A:** corridas sobre un per√≠odo temporal y mes futuro espec√≠ficos, con **5 semillas**.
   - **Grupo B:** mismo enfoque con **10 semillas**, para reforzar la robustez estad√≠stica.
5. Obtener la **ganancia** de cada corrida desde:
   - Leaderboard de Kaggle (Grupo A).
   - Archivos generados en el bucket de resultados (Grupo B).
6. Calcular la **ganancia promedio por m√©todo** y aplicar **test de Wilcoxon** para comparar pares de m√©todos.
7. Comparar resultados entre **Grupo A y B** para evaluar la consistencia.
8. Extraer conclusiones y recomendaciones para el workflow por defecto.

---

## ‚ö†Ô∏è Limitaciones

Algunas limitaciones importantes del experimento:

- **Tiempo y recursos de c√≥mputo** limitados, especialmente cr√≠ticos para DART.
- **DART**:
  - Tiempos de corrida **muy elevados** (en modalidad conceptual lleg√≥ a ~36 horas).
  - Se usaron los **hiperpar√°metros por defecto** del baseline para los par√°metros exclusivos de DART.
  - No fue posible explorar muchas combinaciones alternativas con optimizaci√≥n bayesiana.
- Problemas operativos:
  - M√°quinas virtuales *spot* que se apagaban.
  - Notebooks que se tildaban durante la optimizaci√≥n.
- Diferencias de capacidad de c√≥mputo entre integrantes (no todas las VMs eran equivalentes).

---

## üìä Resultados principales

A partir de las ganancias obtenidas para cada semilla y m√©todo, se construyeron tablas y gr√°ficos comparativos (por grupo y por m√©todo) y se aplic√≥ el **test de Wilcoxon** para contrastar los m√©todos.

**Hallazgos clave:**

- **DART** y **GBDT** presentan **ganancias similares**, sin diferencias estad√≠sticamente significativas seg√∫n el test de Wilcoxon.
- **Random Forest** muestra una **ganancia inferior**, y con m√°s semillas (Grupo B) la diferencia frente a GBDT y DART se vuelve claramente significativa (p-valor ‚â™ 0.05).
- **Tiempo de c√≥mputo**:
  - DART demora aproximadamente **5 veces m√°s** que GBDT.
  - GBDT logra ganancias equivalentes con un tiempo de ejecuci√≥n muy inferior.
- Los resultados de **Grupo A (5 semillas)** y **Grupo B (10 semillas)** son **coherentes y consistentes**, reforzando las conclusiones. 

---

## ‚úÖ Conclusiones

- Dentro de los m√©todos de boosting evaluados de LightGBM, **GBDT y DART** son los que obtienen las **mayores ganancias**.  
- Sin embargo, dado que **DART es mucho m√°s costoso en tiempo de ejecuci√≥n** y la diferencia de ganancia respecto a GBDT **no es estad√≠sticamente significativa**, la opci√≥n **m√°s conveniente para producci√≥n es GBDT**. 
- En entornos reales, donde el tiempo de c√≥mputo se traduce en **costos de procesamiento**, GBDT se presenta como la mejor relaci√≥n **costo‚Äìbeneficio**.
- Estas conclusiones aplican a:
  - Datasets con **caracter√≠sticas similares** a los utilizados.
  - Configuraciones de **hiperpar√°metros optimizados** seg√∫n el workflow de este experimento.

---

## üí° Recomendaciones para el workflow

- Mantener **GBDT** como **m√©todo de boosting por defecto** en el workflow de LightGBM.  
- **No modificar** el c√≥digo por defecto del workflow salvo que haya una justificaci√≥n muy clara y recursos extra para experimentar. 
- Utilizar **Random Forest** solo como modelo r√°pido de referencia inicial, no como modelo final de producci√≥n.
- Considerar **DART** √∫nicamente cuando:
  - Se disponga de **tiempo y c√≥mputo suficientes**.
  - El problema requiera explorar configuraciones avanzadas para maximizar ganancia sin restricciones de tiempo.

---

## üî≠ Trabajo futuro

- Explorar **nuevas combinaciones de hiperpar√°metros** exclusivos de DART (no solo los valores por defecto).
- Probar el experimento en:
  - Otros per√≠odos temporales.
  - Otros datasets con distinta estructura de features.
- Aumentar el n√∫mero de **semillas** para robustecer a√∫n m√°s el an√°lisis estad√≠stico.
